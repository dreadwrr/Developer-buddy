#!/bin/bash
#   Developer buddy 3.0 core                                               08/14/2025
#   saving in tmp filterhits encrypt decrypt postop search searcharr
postop() {
if [ "$POSTOP" == "true" ]; then 
	while IFS= read -r x; do x="${x//$'\\n'/\n}" ; printf '%s\0' "$x"; done < $1 >> $xdata # convert \\n back to \n and \0 for file search
    if [ -f $USRDIR/doctrine.tsv ]; then 
        sed -i 's/^export POSTOP="true"/export POSTOP="false"/' $2 # Avoid calling again unless file removed
    else
        echo -e "Datetime\tFile\tSize(kb)\tType\tModified\tAccessed\tOwner" > $atmp/doctrine
        while IFS= read -r -d '' x; do        
            f="$(cut -d' ' -f3- <<< "$x")"
            dt=$(cut -d' ' -f1-2 <<< "$x")
            if [ -e "$f" ] && [ -f "$f" ]; then  
                onr=$( stat -c "%U" "$f")    
                mtyp=$( file --brief --mime-type "$f") 
                if [ "$mtyp" == "application/octet-stream" ]; then mtyp="Unknown"; fi
                if [ -L "$f" ]; then mtyp="Symlink"; fi
                sz=$( stat -c %s "$f")
                md=$( stat -c '%Y' "$f") ; x=$(date -d "@$md" +'%Y-%m-%d %H:%M:%S') # modification date
                ae=$( stat -c '%X' "$f") ; y=$(date -d "@$ae" +'%Y-%m-%d %H:%M:%S') # access date
                echo -e "$dt\t$f\t$(( sz / 1024 ))\t$mtyp\t$x\t$y\t$onr" >> $atmp/doctrine
            fi
        done < $xdata         
        unset IFS
        head -1 $atmp/doctrine > $USRDIR/doctrine.tsv
        tail -n +2 $atmp/doctrine | sort -t$'\t' -k7,7 -k3,3n >> $USRDIR/doctrine.tsv
        green "File doctrine.tsv created in $USRDIR"
        #column -t -s $'\t' $USRDIR/doctrine.tsv      this command prints a nice tab seperated log
    fi
fi
}
# tmp storage saving remove last one if full    
stmp() {                         
sf=$MODULENAME"_"$FLBRAND
if (( tmpSRHS > 0 )); then #store it in tmp
    test -d /tmp/rc || mkdir /tmp/rc 
	r=$(find /tmp/rc -maxdepth 1 -type f -name '*rntfiles_MDY*' 2>/dev/null | wc -l)
    if [ "$r" -eq "$tmpSRHS" ]; then #Clear last file
        test -f /tmp/rc/full || { touch /tmp/rc/full ; cyan "searches builtup in /tmp/rc"; }
        for file in "/tmp/rc"$MODULENAME"_MDY"*
        do
            rm -f $file
            break
        done
    fi
	awk 'NF' $1 > $TMPCOMPLETE; mv $TMPCOMPLETE $1 
    cp $1 "/tmp/rc"$sf
fi
}
# write stats if filters grep from logfile then pull filter line from filter and send to csv
# $1 logfile $2 csv file
filterhits() {
local lt=$atmp/patterns.txt
local fl=/usr/local/save-changesnew/filter
test -f $2 || echo "Entry,Hits" >> $2
sed -n '/^[[:space:]]*#/!s|sed -i '\''/\(.*\)/d'\''.*|\1|p' "$fl" > $lt
while IFS= read -r pattern; do
    k=$( echo "$pattern" | sed -e 's/\\//g' -e "s|'\"\${2}\"'|$USR|g") #convert for grep
    x=$( grep -Fc -- "$k" $1) # search matches from logs
    if grep -Fq "sed -i '/$pattern/d" $2; then      # in stats file?
        if (( x > 0 )); then
            y=$( grep -F "sed -i '/$pattern/d" $2 | cut -d',' -f2) # count     
            b=$(( y + x ))
            #line=$( grep -Fn "sed -i '/$pattern/d" $2)
            #lno=$( echo "$line" | cut -d: -f1) 
            lno=$(grep -Fn "sed -i '/$pattern/d" "$2" | cut -d: -f1) # get the line# from grep for sed
            sed -i "${lno}s/,[0-9]\+\$/,$b/" $2
        fi
    else #write it to the file
        line=$(grep -F "sed -i '/$pattern/d" "$fl" | grep -v '^[[:space:]]*#')
        if [ "$line" != "" ]; then
            echo "\"$line\",$x" >> $2
        fi
    fi			
done < $lt
unset IFS
rm $lt
}
#create/open and save encrypted log/stats gpg $1 logfile $2 output
storeenc() {
local c
    if [ "$STATPST" == "true" ]; then # Requires encryption
        if ! gpg --list-keys | grep -q $email; then #gpg --full-generate-key
            echo pwd $PWD
            read -sp "Enter passphrase for new GPG key: " p
            echo
            #read -sp "Confirm passphrase: " passphrase_confirm
            #echo
            #if [ "$passphrase" != "$passphrase_confirm" ]; then
            #    echo "Passphrases do not match. Aborting."
            #    exit 1
            #fi
cat > /tmp/keyparams.conf <<EOF
%echo Generating a GPG key
Key-Type: RSA
Key-Length: 4096
Subkey-Type: RSA
Subkey-Length: 4096
Name-Real: John Doe
Name-Email: $email
Expire-Date: 0
Passphrase: $p
%commit
%echo done
EOF
        gpg --batch --pinentry-mode loopback  --passphrase "$p" --generate-key /tmp/keyparams.conf
        shred -u /tmp/keyparams.conf
        echo "GPG key generated for ${email}."
        fi
        if grep -m 1 -q '^Modified,' $1; then msg=" stats"; else msg=" log"; fi
        if [ -s "$2" ]; then
			if [ "$3" != "dcr" ]; then
				if ! decrypt $xdata $2; then
		            echo "Failed to decrypt  $2$msg"
		            echo "decrypt $2$msg failed"
		            return 1
		        fi
				source=$xdata
			else
				source=$xdata2
			fi
            if [ "$msg" == " stats" ]; then  
				declare -A ref_map  # Load the database          As we at 300 searches this is far more efficient than grepping the entire file its in assosiative array
				while IFS="" read -r line || [ -n "$line" ]; do
					key=$(awk -F'"' '{print $2}' <<< "$line" )
					[[ -n "$key" ]] && ref_map["$key"]="$line"
				done < $source
                while IFS="" read -r p || [ -n "$p" ]; do
                    ft=$(echo "$p" | cut -d',' -f1)       # Action | tr -d '"')   optional ""                   Modified, Delete  field
					if [ "$ft" == "Nosuchfile" ]; then # We want to keep track of any occurence of this         filepath=$( echo "$p" | awk -F',' '{ gsub(/^"|"$/, "", $3); print $3 }')
						filepath=$(echo "$p" | cut -d',' -f3- | sed 's/^ *//;s/ *$//')
						entry="Nosuchfile,,${filepath}"
						echo "$entry" >> $source
					else
		                dt=$(echo "$p" | cut -d',' -f2 | tr -d '"')   	 #  , "date time" 
						filepath=${p#*,*,}  # returns after 2nd ,
						if [[ ! -v ref_map["$filepath"] ]]; then #if [ ! -n "$found_line" ]; then
			                entry="$ft,\"${dt}\",${filepath}"
			                echo "$entry" >> $source
						fi
					fi
                done < $1
                unset IFS
            else # its a log
                c=$( grep -c '^$' $source) # line count blank line sep
                if  (( c == logCT )); then 
                    sed -i '1,/^$/d' $source  # Remove the top one
                fi
                cat $1 >> $source #sed '/NOTA-FI-LE 77:77:77/d' $1     # We either delete these here or in query if wanted but stats are useful
                echo >> $source # end of log
            fi


            cmmd=(gpg --yes -e -r $email -o $2 $source) # normal usage
			if [ "$nc" == "true" ]; then cmmd=(gpg --yes --compress-level 0 -e -r $email -o $2 $source); fi # If over the size limit disable compression for speed
			if ! "${cmmd[@]}"; then  # Encrypt
				echo "Encryption failed for file: $source  . $2$msg "
				return 1
			fi
            #shred -u $source
            rm $source
            if [ "$msg" == " log" ]; then echo $c; fi
        else
            echo >> $1
            if ! gpg --yes -e -r $email -o $2 "$1"; then #encrypt
                echo "Encryption failed for file: $1"
                return 1
            fi
            echo "The${msg} was created."
        fi
    fi
}
decrypt(){	if ! gpg --yes -d -o $1 $2; then return 1; fi; } #decrypt  
# Actions  Overwite Metadata Replaced Modified Csumchng
# Effectively parse only when absolutely necessary. Use assosiative array locally safe for 300 searches. for parallel as only 8 files regular array
hanly(){
	local csm=""
	local cores=""
	>$tfile
	if [ "$mMODE" == "mc" ]; then
		cores=$(nproc 2>/dev/null || echo 1)
		max_jobs=$cores
		if (( max_jobs > 16 )); then max_jobs=16; fi
		split -l 8 "$SORTCOMPLETE" "$atmp/sortchunk_"
		ls "$atmp"/sortchunk_* | xargs -P"$max_jobs" -I{} /usr/local/save-changesnew/haloop "$atmp" "{}" "$2" "$checkSUM"
		#ls "$atmp"/sortchunk_* | xargs -P4 -I{} /usr/local/save-changesnew/haloop "$atmp" "{}" "$2" "$checkSUM"
		if compgen -G $atmp/haloop1_*_tmp.log > /dev/null; then cat "$atmp"/haloop1_*_tmp.log >> $rout; fi
		if compgen -G $atmp/haloop2_*_tmp.log > /dev/null; then cat "$atmp"/haloop2_*_tmp.log >> $tfile; fi
	else
		declare -A ref_map  # Load the database
		while read -r line; do
			key=$(echo "$line" | awk -F'"' '{print $2}')
			ref_map["$key"]="$line"
		done < $2 # Our logpst
		while IFS="" read -r p || [ -n "$p" ]; do                
			#cFILE=$(echo "$p" | awk -F'"' '{print $2}')
			cFILE=$(echo "$p" | sed -n 's/[^"]*"\(.*\)".*/\1/p')		 #perl -lne 'print $1 if /"(.*)"/'
			y="$cFILE" # Label human readable
			current_ln="${p//\"$cFILE\"/}" # Remove the " path file "
			current_ln="$(echo "$current_ln" | xargs)"            
			in=$(echo "$current_ln" | cut -d " " -f3) # Current inode
			if [ -n "$in" ] && [ "$in" -ge 0 ] 2>/dev/null; then # The format for current is at least correct .. this far
				found_line="${ref_map[$y]}"
				if [ -n "$found_line" ]; then #if grep -qsF "\"$y\"" $2; then	 # start here	
					sline="$found_line" # Lets make sure we have both sets of data before we fully parse
					original_ln="${sline//\"$cFILE\"/}" # Remove the " file path "
					original_ln="$(echo "$original_ln" | xargs)" 
					cFILE="${cFILE//$'\\n'/\n}" # Convert from human readable
					oin=$(echo "$original_ln" | cut -d " " -f3) # Original inode
					if [ -n "$oin" ] && [ "$oin" -ge 0 ] 2>/dev/null; then # Format original good we can parse the rest of the data
						omt=$(echo "$original_ln" | cut -d " " -f1-2)
						oat=$(echo "$original_ln" | cut -d " " -f4-5) 
						org=$(echo "$original_ln" | cut -d " " -f6) #
						t=$(date -d "$oat" +%s 2>/dev/null)   
						k=$(date -d "$cat" +%s 2>/dev/null)
						dt=$(echo "$current_ln" | cut -d " " -f1-2)
						cat=$(echo "$current_ln" | cut -d " " -f4-5) 
						cs=$(echo "$current_ln" | cut -d " " -f6)
						if [ "$dt" == "$omt" ]; then # Not a candidate we want but if checkSUM is on you believe you do
							if [ "$checkSUM" == "true" ]; then # Bonus output is checksum on	
								if [ -n "$t" ] && [ -n "$k" ]; then # two key verification to be sure we are at the checksum  format is perfect
									if [ -n "$org" ] && [ -n "$cs" ] && [ -f "$cFILE" ]; then	# format is looking good.
										csze=$(echo "$current_ln" | cut -d " " -f7-) # current size
										os=$(echo "$original_ln" | cut -d " " -f7-)
										if [ -n "$csze" ]; then # Perfect format now
											if [ "$org" != "$cs" ]; then # suspicious
												a_checksum=$(md5sum "$cFILE" | awk '{print $1}') 
												a_mod=$(stat --format=%Y "$cFILE")
												afrm=$(date -d "@$a_mod" +"%Y-%m-%d %H:%M:%S")
												if [ -n "$os" ] && [ -n "$afrm" ]; then # Ensure the file is still there
													if [ "$afrm" == "$dt" ]; then #flag
														echo "Csumc $dt $y"| tee -a "$rout" >> "$tfile"| tee -a /tmp/cerr; csm="true"	
													else
														if [ "$a_checksum" != "$cs" ] && [ "$cdiag" == "true" ]; then # Changed during search
															echo "File changed during the search. ${y} at ${afrm}. Size was $os, now $fs. " >> /tmp/scr
														elif [ "$a_checksum" != "$cs" ]; then
															echo "File changed during search ${y}. File likely changed. system cache item." >> /tmp/scr
														fi
													fi	
												fi
											else
												stealth $cFILE $os $csze $y $cdiag "csum" # file collision or file was edited in such as way that its checksum is exactly the same? swith to sha256
											fi
										fi
									fi
								fi
							fi
						else # Regular but What changed?
							if (( oin != in )); then # Inode changed normal
								if [ "$checkSUM" == "true" ]; then # More accurate
									if [ -n "$org" ] && [ -n "$cs" ]; then	# Ensure we actually have both checksums
										if [ "$org" == "$cs" ]; then # same checksum file copied over
											echo "Overwrt $dt $y" | tee -a $rout >> "$tfile"
										else # New file
											os=$(echo "$original_ln" | cut -d " " -f7)
											csze=$(echo "$current_ln" | cut -d " " -f7-)
											if [ -n "$t" ] && [ -n "$k" ]; then
												if [ -n "$csze" ]; then stealth $cFILE $os $csze $y $cdiag ;fi
											fi
											echo "Replaced $dt $y" | tee -a $rout >> "$tfile"
										fi
									fi
								else # We have just given more info than the diff file with Inode change
									echo "Replaced $dt $y" | tee -a $rout >> "$tfile"
								fi
							else # Same Inode
								if [ "$checkSUM" == "true" ]; then
									if [ -n "$org" ] && [ -n "$cs" ]; then	# Ensure we actually have both checksumslogfile=$(mktemp /tmp/haloop1_XXXXXX.log)
										if [ "$org" != "$cs" ]; then
											os=$(echo "$original_ln" | cut -d " " -f7-)
											csze=$(echo "$current_ln" | cut -d " " -f7-)
											if [ -n "$t" ] && [ -n "$k" ]; then
												if [ -n "$csze" ]; then stealth $cFILE $os $csze $y $cdiag ;fi
											fi
											echo "Modified $dt $y" | tee -a $rout  >> $tfile # File has new content
										else
											echo "Touched $dt $y" | tee -a $rout >> $tfile # Something minor
										fi
									fi
								else # Regular mode
									echo "Modified $dt $y" | tee -a $rout >> $tfile # We have different time and indication of change. 
								fi
							fi
						fi
					fi
				fi
			fi
		done < $1 #SORTCOMPLETE
		unset IFS
	fi
	rm $2
    processha
}
processha() {
    if [ -s $rout ]; then
        if [ -s $tfile ]; then
            echo >> "$difffile"
            echo "Hybrid analysis" >> "$difffile"
            echo >> "$difffile"
			#sed -E 's/^([^,]+),"([^"]+)","([^"]+)"$/\1 \2 \3/' $tfile # rev from csv 
			sort -o $tfile $tfile
			if [ -s $ABSENT ]; then sort -o $ABSENT $ABSENT; comm -23 $tfile $ABSENT > $TMPCOMPLETE ; else cat $tfile > $TMPCOMPLETE ; fi #   ; else  cat $tfile > $TMPCOMPLETE; fi # We dont want anything already in written
			if [ "$flsrh" == "true" ] || [ "$3" == "filtered" ]; then  # Filter the view for filtered searches. A file search or rn	
			     if ! { [ "$flsrh" == "true" ] && [ "$3" == "filtered" ]; } ; then	# If flsrh and $3 is filtered its inverse from  rnt  so we dont want to filter this time																																					    	
				 /usr/local/save-changesnew/filter $TMPCOMPLETE $USR 
			     fi
			fi
			if [ "$flsrh" == "true" ]; then   # We only want files newer than the file in the results
				cDATE=$( head -n1 $TMPOPT | awk '{print $1 " " $2}')          
				awk -v tme="$cDATE" '$0 >= tme' "$TMPCOMPLETE" > $TMPOUTPUT
				cp $TMPOUTPUT $TMPCOMPLETE
			fi
			#awk '{ printf "%s%s\n", $1, substr($0, length($1)+2) }' $TMPCOMPLETE >> "$difffile"
			
			awk '{printf "%-10s %-25s %-60s\n", $1, $2" "$3, $4}' $TMPCOMPLETE >> "$difffile"
       		if [ "$csm" != "" ]; then echo "csum"; else [ -n "$cores" ] && echo "$cores"; fi
        fi
	fi
}
search() {
while IFS= read -r -d '' x; do
	adtcmd="" ; output="" ; fs=""
	y="${x//$'\n'/\\n}"
	if [ -e "$x" ] && [ -f "$x" ]; then
		stat_out=$(stat -c "%Y %X %i" "$x")
		read -r f atime i <<<"$stat_out"
		mt=$(date -d "@$f" +"%Y-%m-%d %H:%M:%S")
		ats=$(date -d "@$atime" +"%Y-%m-%d %H:%M:%S")
		if [ -n "$mt" ]; then  # This at least ensures the format is correct if there is no date
			if [ "$checkSUM" == "true" ]; then
				csum=$(md5sum "$x")  #csum=$(md5sum "$x" | awk '{print $1}')
				csum=${csum%% *}
				fs=$(stat --format=%s "$x") 
				adtcmd="$csum $fs"
			fi	
			output="$mt \"$y\" $i $ats $adtcmd"
			printf '%s\n' "$output" >> $2
		fi
	else
		printf 'NOTA-FI-LE 77:77:77 "%s"\n' "$y" >> $2
		printf 'Nosuchfile,,%s\n' "$y" >> $3
	fi
done < $1
unset IFS
}
searcharr () {
while IFS= read -r -d '' x; do
	adtcmd="" ; output="" ; fs=""
	y="${x//$'\n'/\\n}"
	if [ -e "$x" ] && [ -f "$x" ]; then
		stat_out=$(stat -c "%Y %X %i" "$x")
		read -r f atime i <<<"$stat_out"
		mt=$(date -d "@$f" +"%Y-%m-%d %H:%M:%S")
		ats=$(date -d "@$atime" +"%Y-%m-%d %H:%M:%S")
		if [ -n "$mt" ]; then  # This at least ensures the format is correct if there is no date
			if [ "$checkSUM" == "true" ]; then
				csum=$(md5sum "$x")  #csum=$(md5sum "$x" | awk '{print $1}')
				csum=${csum%% *}
				fs=$(stat --format=%s "$x") 
				adtcmd="$csum $fs"
			fi
			output="$mt \"$y\" $i $ats $adtcmd"
			ffile+=("$output")
		fi
	else
		ffile+=("NOTA-FI-LE 77:77:77 \"$y\"")
		nsf+=("Nosuchfile,,$y")
	fi
done < $1
unset IFS
}
 #called for two diff searched flt or unflt clear old logs  sed "s|^/||g"
clearlogs() { 
    local suffixes=(
        "xSystemDiffFromLastSearch"
        "xFltDiffFromLastSearch"
        "xFltchanges"
        "xFltTmp"
        "xSystemchanges"
        "xSystemTmp"
        "xNewerThan"
        "xDiffFromLast_"
    )
for suffix in "${suffixes[@]}"; do rm -f "${MODULENAME/#\//}$suffix"* 2>/dev/null ; done 
}
stealth() {
local file="$1"
local original_size="$2"
local current_size="$3"
local label="$4"  # \n \\n
local diag="$5"
if [ -f "$file" ] && [ "$diag" == "true" ]; then
	local a_mod
	local afrm
	a_mod=$(stat --format=%Y "$file") # actual modified tm fs=$(stat --format=%s "$cFILE") # actual size
	afrm=$(date -d "@$a_mod" +"%Y-%m-%d %H:%M:%S") # UTC 
	if [ -n "$original_size" ] && [ -n "$current_size" ] && [ -n "$afrm" ]; then #format
		local delta=$(( current_size - original_size ))
		local abs_delta=${delta#-}
		if [ "$abs_delta" -le 3  ] && [ "$abs_delta" -ne 0 ]; then
			echo "Checksum indicates a change in ${label}. Size changed slightly — possible stealth edit. ($original_size → $current_size)." >> /tmp/scr
		elif [ "$abs_delta" -ne 0 ] && [ "$6" == "csum" ]; then # rare event
			echo "File collision ${label}. Same modified date and checksum. Either md5 is too weak or file was edited and matches exact checksum." >> /tmp/cerr # flag
		fi
	fi
fi
}

